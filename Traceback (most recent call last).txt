
DF Team - Enhance/New integration pattern to extract the data from AS400 System - Additional Interest (SQS)

import os
import json
import time
import asyncio
import pandas as pd
from datetime import datetime
from sqlalchemy.exc import SQLAlchemyError

import boto3
from botocore.exceptions import ClientError

from df_database_models.db_conn import get_rds_db_session, get_as400_db_session
from df_database_models.models import Additional_Interest, Source_System
from df_database_models.db_utils import generate_uuid, query_update_dict, get_record, convert_timestamps
from adf_pyutils.clm_wrapper import common_logger
from secrets_manager import get_secret

print("AS400 Additional Interest ETL job executing...")

# --- AWS RDS + SQS Setup ---
sqs_queue_url = os.environ["SQS_QUEUE_URL"]
sqs = boto3.client("sqs", region_name=os.environ["AWS_REGION"])

rds_secret_name = os.environ["RDS_SECRETS_MANAGER_ID"]
region_name = os.environ["AWS_REGION"]
rds_host = os.environ["RDS_HOST"]
rds_db = os.environ["RDS_DB_NAME"]

session = get_rds_db_session(rds_secret_name, region_name, rds_host, rds_db)

async def log_msg(func, **kwargs):
    await asyncio.to_thread(func, **kwargs)

def call_session_engine(source_system=None, identifier=None):
    rds_secret_name = os.environ["RDS_SECRETS_MANAGER_ID"]
    region_name = os.environ["AWS_REGION"]
    rds_host_nm = os.environ['RDS_HOST']

    if identifier == 'ref':
        rds_db_nm = os.environ['RDS_REF_DB_NAME']
    elif identifier == 'raw':
        rds_db_nm = os.environ['RDS_RAW_DB_NAME']
    elif identifier == 'refined':
        rds_db_nm = os.environ['RDS_REFINED_DB_NAME']
    else:
        rds_db_nm = os.environ['RDS_DB_NAME']

    if source_system.lower() == 'as400_aff':
        as400_secret_name = os.environ["AS400_AFF"]
        as400_engine = get_as400_db_session(as400_secret_name, region_name)
    elif source_system.lower() == 'as400_aum':
        as400_secret_name = os.environ["AS400_AUM"]
        as400_engine = get_as400_db_session(as400_secret_name, region_name)
    else:
        raise Exception(f"Unsupported source system {source_system}")

    session = get_rds_db_session(rds_secret_name, region_name, rds_host_nm, rds_db_nm)
    return session, as400_engine

# --- Lookup Additional Interest from AS400 ---
def lookup_as400_additional_interest(config=None):
    source_system = config['source_system']
    if source_system:
        if source_system.lower() in ['as400_aff', 'as400_aum']:  # extend if needed
            df = pd.read_sql(f"""
                SELECT 
                    ai_id AS source_additional_interest_id,
                    name,
                    address,
                    city,
                    state,
                    zip,
                    created_ts AS created_date,
                    updated_ts AS modified_date
                FROM AS400_ADDITIONAL_INTEREST_TABLE
            """, con=as400_engine)  # uses global as400_engine
        else:
            df = None
    else:
        df = None

    if df is not None and len(df) > 0:
        return df.to_dict('records')[0]  # single record
    else:
        return None

# --- Publish to SQS ---
def publish_to_sqs(message):
    try:
        response = sqs.send_message(
            QueueUrl=sqs_queue_url,
            MessageBody=json.dumps(message)
        )
        return response
    except ClientError as e:
        print(f"Error sending to SQS: {str(e)}")
        raise

# --- Main Consumer Function ---
async def consume_lambda(config=None):
    try:
        asyncio.create_task(log_msg(common_logger, log_messages='consume lambda function invoking'))
        now = datetime.now()
        start_timestamp = datetime.timestamp(now)
        asyncio.create_task(log_msg(common_logger, log_messages=f'Processing to DB @ {now}'))

        config_dicts = config if isinstance(config, list) else [json.loads(config) if isinstance(config, str) else config]

        for config_dict in config_dicts:
            source_system = config_dict["source_system"]
            additional_interest_id = config_dict["additional_interest"]  # ðŸ”¹ instead of carrier

            global session, as400_engine
            session, as400_engine = call_session_engine(source_system=source_system)

            asyncio.create_task(log_msg(common_logger, log_messages=f"Fetching Additional Interest {additional_interest_id} from {source_system}"))

            as400_ai = lookup_as400_additional_interest(config_dict)
            if as400_ai:
                # --- Map Source System ---
                source_system_record = (
                    query.first() if (query := get_record(
                        session, model=Source_System, column_name="source_system", value=source_system)) else None
                )
                if source_system_record:
                    as400_ai["df_source_system_id"] = source_system_record.df_source_system_id

                # --- Additional Interest DF ID ---
                df_ai_id = generate_uuid(str(as400_ai["source_additional_interest_id"]), as400_ai["df_source_system_id"])
                as400_ai["df_additional_interest_id"] = df_ai_id

                # --- Check if Additional Interest already exists ---
                ai_record = get_record(session, model=Additional_Interest,
                                       column_name="source_additional_interest_id",
                                       value=as400_ai["source_additional_interest_id"],
                                       df_source_system_id=as400_ai["df_source_system_id"])
                self_ai = ai_record.first() if ai_record else None

                if self_ai is None:
                    session.add(Additional_Interest.from_dict(cls=Additional_Interest, d=as400_ai))
                    asyncio.create_task(log_msg(common_logger, log_messages=f"Inserted new Additional Interest {additional_interest_id}"))
                else:
                    self_ai.update(query_update_dict(obj=Additional_Interest, dict=as400_ai))
                    asyncio.create_task(log_msg(common_logger, log_messages=f"Updated Additional Interest {additional_interest_id}"))

                session.commit()

                # --- Send to SQS ---
                publish_to_sqs(as400_ai)

            else:
                asyncio.create_task(log_msg(common_logger, log_messages=f"No record found for Additional Interest {additional_interest_id}"))

        end_timestamp = datetime.timestamp(datetime.now())
        asyncio.create_task(log_msg(common_logger, log_messages=f'execution_time: {end_timestamp - start_timestamp}'))

    except SQLAlchemyError as e:
        session.rollback()
        asyncio.create_task(log_msg(common_logger, log_messages="DB Error", api_response=str(e)))
        raise e

def handle(event, context):
    start_time = time.time()
    for record in event["Records"]:
        payload = record["body"]
        asyncio.run(consume_lambda(config=payload))
    return {"execution_time_sec": time.time() - start_time}

